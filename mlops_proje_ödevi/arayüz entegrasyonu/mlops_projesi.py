# -*- coding: utf-8 -*-
"""MLOPS projesi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ry4ROTLf19i-GXFS6q7AvPkW2Jp3CHn9
"""
import os
os.environ['DISPLAY'] = ':0.0'
os.environ["GIT_PYTHON_REFRESH"] = "quiet"
import git

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import datetime
import matplotlib.pyplot as plt
# %matplotlib inline
from pandas.plotting import scatter_matrix
from sklearn import model_selection
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from tqdm import tqdm
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.linear_model import BayesianRidge
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import OrdinalEncoder
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix as cm
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
#from sklearn.cross_validation import train_test_split
from sklearn.metrics import accuracy_score 
from sklearn.model_selection import cross_val_score
from sklearn.impute import SimpleImputer
from sklearn.pipeline import make_pipeline
import warnings
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split, KFold
import mlflow
import mlflow.sklearn
warnings.filterwarnings('ignore')
import ipywidgets as widgets
from ipywidgets import interact, interactive, fixed, interact_manual
df=pd.read_csv('seattle-weather.csv')
df1=pd.DataFrame(df)
df.head()
import tkinter as tk
from tkinter import messagebox

#Kolon sayısı
kolon_sayisi = len(df.columns)

#Satır sayısı
satir_sayisi = len(df)


#Sütun isimlerini görüntüleme
columns = list(df.columns)

#Veri tiplerini görüntüleme
#print("\nVeri Türleri: ", df.dtypes)

"""
# Satır ve sütun ortalamalarını hesapla.
row_averages = df.mean(axis=1)
column_averages = df.mean(axis=0)

print("Satır Ortalamaları:\n", row_averages, "\n")
print("Sütun Ortalamaları:\n", column_averages)
"""
# Null değerleri saymak için `isnull()` fonksiyonunu kullanarak boolean bir veri çerçevesi oluşturuyoruz
# Ardından, `sum()` fonksiyonunu kullanarak her sütundaki null değerlerin toplam sayısını hesaplıyoruz
null_sayisi = df.isnull().sum()

# # Veri seti eksik değerlerin yüzdesini hesaplar
df.isnull().sum()*100/len(df)

unique_values = df['weather'].unique()
"""
dates = [datetime.datetime.strptime(ts, "%Y-%m-%d") for ts in df['date']]
dates.sort()
sorteddates = [datetime.datetime.strftime(ts, "%Y-%m-%d") for ts in dates]
df['date'] = pd.DataFrame({'date':sorteddates})
df['Year'], df['Month'],  df['Day'] = df['date'].str.split('-').str
"""
# Veri setini yükleme ve 'date' sütununu düzenleme
df['date'] = pd.to_datetime(df['date'])
df.sort_values(by='date', inplace=True)
df['date'] = df['date'].dt.strftime('%Y-%m-%d')

# 'date' sütununu ayırma
df[['Year', 'Month', 'Day']] = df['date'].str.split('-', expand=True)

unique_values = df['weather'].unique()

#date sütununu silmek
df = df.drop(['date'], axis=1)

# Yinelenen satırları kaldırma
df = df.drop_duplicates()
        
# String değerlere Label Encoding uygulama
label_encoder = LabelEncoder()
string_columns = df.select_dtypes(include=['object']).columns
df[string_columns] = df[string_columns].apply(label_encoder.fit_transform)

# Integer değerlere ortalama ile eksik değerleri doldurma
integer_columns = df.select_dtypes(include=['int', 'float']).columns
df[integer_columns] = df[integer_columns].fillna(df[integer_columns].mean())
        
# String değerlere "Bilinmiyor" ile eksik değerleri doldurma
string_columns = df.select_dtypes(include=['object']).columns
df[string_columns] = df[string_columns].fillna("Bilinmiyor")

# Bağımsız değişkenleri ve hedef değişkeni ayırma
X = df.drop("weather", axis=1)  # Bağımsız değişkenler
Y = df["weather"]  # Hedef değişken

# Veri setini eğitim ve test kümelerine ayırma
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.01, random_state=16)

"""1)Model Eğitimi: MLflow, farklı model algoritmalarını ve hiperparametre ayarlarını denemek için kullanılabilir. MLflow'un entegre olduğu makine öğrenimi kütüphaneleri ile eğitim süreçlerinizi izleyebilir, model ağırlıklarını ve hiperparametreleri kaydedebilir ve sonuçları karşılaştırabilirsiniz.

2)Model Değerlendirme ve Performans İzleme: MLflow, modelinizi değerlendirmek ve performansını izlemek için kullanılabilir. Metrikleri kaydedebilir, farklı modellerin performansını karşılaştırabilir ve hata analizi yapabilirsiniz.
"""

mlflow.end_run()
"""
# MLflow oturumu başlatılır
mlflow.start_run()

# Modellerin listesi oluşturulur
models = [
    ("LR", LogisticRegression()),
    ("LDA", LinearDiscriminantAnalysis()),
    ("KNN", KNeighborsClassifier()),
    ("DT", DecisionTreeClassifier()),
    ("NB", GaussianNB()),
    ("SVM", SVC()),
    ("RF", RandomForestClassifier()),
    ("KA", DecisionTreeClassifier())
]

# K-fold cross-validation için kullanılacak n_splits değeri
n_splits = 10

# Modeller için cross validation sonuçlarının kaydedilmesi ve yazdırılması
for name, model in models:
    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=7)
    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring="accuracy")
    
    # Model performans metriklerinin kaydedilmesi
    mlflow.set_tag("model_name", name)
    mlflow.log_metrics({"accuracy_mean": cv_results.mean(), "accuracy_std": cv_results.std()})
    
    # Modelin MLflow üzerinde kaydedilmesi
    mlflow.sklearn.log_model(model, name)
    
    print("%s: %f (%f)" % (name, cv_results.mean(), cv_results.std()))

# MLflow oturumu sonlandırılır
mlflow.end_run()

#3)Model İzleme ve Yeniden Eğitim: MLflow, dağıtılmış modellerinizi izleyebilir, gerçek zamanlı tahmin sonuçlarını kaydedebilir ve geri bildirimleri değerlendirebilirsiniz. Ayrıca, modelinizi sürekli olarak yeniden eğitebilir ve güncelleyebilirsiniz.

# Parametre aralıklarını belirleme
test_size_range = [0.1, 0.2, 0.3, 0.4, 0.5]
random_state_range = list(range(0, 101))
max_depth_range = list(range(1, 11))

best_accuracy = 0.0
best_params = {}

# Parametre kombinasyonlarını döngüyle oluşturma
for test_size in test_size_range:
    for random_state in random_state_range:
        for max_depth in max_depth_range:
            # Veri setini eğitim ve test kümelerine bölme
            X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)

            # Random Forest sınıflandırıcı modelini oluşturma
            rf = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=random_state)

            # Modeli eğitme
            rf.fit(X_train, Y_train)

            # Tahminleri yapma
            Y_pred = rf.predict(X_test)

            # Kesinlik skorunu hesaplama
            accuracy = accuracy_score(Y_test, Y_pred)

            # En iyi parametreleri güncelleme
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_params = {'test_size': test_size, 'random_state': random_state, 'max_depth': max_depth}

# En iyi parametreleri yazdırma
print("En iyi parametreler: ", best_params)
print("En iyi kesinlik skoru: ", best_accuracy)
mlflow.end_run()
"""
# Random Forest sınıflandırıcı modelini oluşturma
rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=92)
# Modeli eğitme
rf.fit(X_train, Y_train)

best_params = {"max_depth": 10, "random_state":92, 'test_size':0.1}
best_accuracy = 0.8

# MLflow oturumu başlatılır
mlflow.start_run()

# Model eğitimi
model = RandomForestClassifier(n_estimators=100, max_depth=best_params['max_depth'],
                               random_state=best_params['random_state'])
model.fit(X_train, Y_train)

# Eğitim sonuçları ve model kaydedilir
mlflow.log_params({"test_size": best_params['test_size'],
                   "random_state": best_params['random_state'],
                   "max_depth": best_params['max_depth']})
mlflow.log_metrics({"accuracy": best_accuracy})
mlflow.sklearn.log_model(model, "model")

# MLflow oturumu sonlandırılır
mlflow.end_run()

# Eğitim ve test veri setleri üzerinde tahmin yapma
Y_train_pred = model.predict(X_train)
Y_test_pred = model.predict(X_test)

# Tahminlerin performansını değerlendirme
train_mse = mean_squared_error(Y_train, Y_train_pred)
test_mse = mean_squared_error(Y_test, Y_test_pred)

#print("Eğitim veri seti hata kare ortalaması (MSE):", train_mse)
#print("Test veri seti hata kare ortalaması (MSE):", test_mse)

# Gerçek hava durumu
Y_train_true = Y_train.values
Y_test_true = Y_test.values

# Tahmin edilen hava durumu
Y_train_pred = model.predict(X_train)
Y_test_pred = model.predict(X_test)

# Gerçek hava durumu ve tahmin edilen hava durumunu birleştirme
train_results = pd.DataFrame({'Gerçek hava durumu': Y_train_true, 'Tahmini hava durumu': Y_train_pred})
test_results = pd.DataFrame({'Gerçek hava durumu': Y_test_true, 'Tahmini hava durumu': Y_test_pred})

# Sonuçları ekrana yazdırma
#print("Eğitim veri seti:")
#print(train_results.head())

#print("\nTest veri seti:")
#print(test_results.head())

unique_values = df['weather'].unique()
#print("Farklı veri sayısı:", len(unique_values))

value_counts = df['weather'].value_counts()
#print("Farklı veri sayısı:", len(value_counts))

unique_values = df['weather'].unique()
#print("Farklı değerler:")


def predict_weather(yagis, maxsicaklik, minsicaklik, ruzgar, gun, ay, yil):
    new_data = {}

    new_data['precipitation'] = yagis
    new_data['temp_max'] = maxsicaklik
    new_data['temp_min'] = minsicaklik
    new_data['wind'] = ruzgar
    new_data['Year'] = yil
    new_data['Month'] = ay
    new_data['Day'] = gun

    new_df = pd.DataFrame(new_data, index=[0])
    label_encoder = LabelEncoder()

    # Yeni verilerin dönüştürülmesi
    string_columns = new_df.select_dtypes(include=['object']).columns
    new_df[string_columns] = new_df[string_columns].apply(label_encoder.fit_transform)

    # Eğitim veri setindeki sütunlarla yeni veri seti arasında eşleştirme
    new_df = new_df.reindex(columns=X.columns, fill_value=0)

    prediction = rf.predict(new_df)

    if prediction == 0:
            message = "drizzle"
    elif prediction == 1:
            message = "fog"
    elif prediction == 2:
            message = "rain"
    elif prediction == 3:
            message = "snow"
    else:
            message = "sun"

    return message



def durum(prediction):
    if prediction == 0:
        messagebox.showinfo("Hava Durumu Tahmini", "Tahminlerimize göre hava durumu: drizzle")
    elif prediction == 1:
        messagebox.showinfo("Hava Durumu Tahmini", "Tahminlerimize göre hava durumu: fog")
    elif prediction == 2:
        messagebox.showinfo("Hava Durumu Tahmini", "Tahminlerimize göre hava durumu: rain")
    elif prediction == 3:
        messagebox.showinfo("Hava Durumu Tahmini", "Tahminlerimize göre hava durumu: snow")
    else:
        messagebox.showinfo("Hava Durumu Tahmini", "Tahminlerimize göre hava durumu: sun")
